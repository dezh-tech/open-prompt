{
  // Prompt name
  "name": "Example Agent",
  // A short description of what the prompt is about
  "description": "Example Description",
  // Version of the prompt (semantic versioning 2.0.0 spec)
  "promptVersion": "1.0.0",
  // Open prompt standard version
  "opVersion": "v1",
  // A list of LLM model names that can be used
  "models": [
    "MODEL NAME HERE"
  ],
  // Source files: prompt and documentation
  "source": {
    "prompt": "v1.j2",
    "doc": "v1.md"
  },
  // Sampling parameters to guide LLM behavior
  "sampling": {
    "temp": 0.5, // Temperature: randomness level
    "topK": 15, // Top-K sampling: restricts to top K tokens
    "topP": 0.3 // Top-P (nucleus) sampling: restricts to top P probability mass
  },
  // Controls the output format and behavior
  "outputControl": {
    "maxTokens": 1, // Max tokens in the output
    "stopSeq": "###", // Sequence that stops generation
    "repetitionPenalty": 1, // Penalize repeating words
    "frequencyPenalty": 1, // Penalize frequent words
    "presencePenalty": 1, // Penalize previously mentioned words
    "structure": "plain" // Output format type
  },
  // Replaceable variables used in the prompt
  "variables": {
    "example_var": {
      "type": "", // Type can be: 1. type name (string, bool, int, float, object) 2. Example value which indicated the type as well. 
      "description": "", // A description of what this variable is.
      "default": "" // What will be replaced if you don't provide a value.
    }
  }
}
